{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31e654d-1ade-4c92-b1c4-d8e1e3711807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57f4aa6-c01d-4812-aa0c-bc379e0eb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('hand_recognition_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8612ab6d-f721-4b25-bfba-693df983999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['palm', 'l', 'fist', 'fist_moved', 'thumb']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e90a316-cfc0-47cc-8c73-1ac9c4769b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq\\\\backend\\\\cython\\\\checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3, 1280)\n",
    "camera_video.set(4, 960)\n",
    "\n",
    "cv2.namedWindow('Fingers Counter', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while camera_video.isOpened():\n",
    "\n",
    "    ok, frame = camera_video.read()\n",
    "    if not ok:\n",
    "        continue\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "            break\n",
    "\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2b332-4f0f-473b-9785-41cad0a7dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "#if not cap.isOpened():\n",
    "    #print(\"Error: Could not open webcam.\")\n",
    "   # exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60054565-c9ed-469f-a549-73a53a2fb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    " try:\n",
    "        # Preprocess the frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (640, 240))\n",
    "        normalized = resized / 255.0\n",
    "        input_arr = np.array([normalized])\n",
    "        input_arr = np.expand_dims(input_arr, axis=-1)\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = model.predict(input_arr)\n",
    "        class_index = np.argmax(prediction)\n",
    "\n",
    "       # Make prediction\n",
    "        prediction = model.predict(input_arr)\n",
    "        class_index = np.argmax(prediction)\n",
    "\n",
    "        # Robust index checking - ALWAYS define class_name and confidence\n",
    "        if 0 <= class_index < len(class_names):\n",
    "            class_name = class_names[class_index]\n",
    "            confidence = prediction[0][class_index]\n",
    "        else:\n",
    "            class_name = \"Unknown\"\n",
    "            confidence = 0.0\n",
    "            # VERY CAREFULLY copy this line\n",
    "            print(f\"Warning: Predicted class index out of range: {class_index}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c6a26-fad9-4c78-897b-fbdfd94e6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "        cv2.putText(frame, f'Prediction: {class_name} ({confidence:.2f})', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.imshow('Hand Gesture Recognition', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f206bc9-108c-49c5-87c3-9ea88370ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "     except Exception as e:\n",
    "        print(f\"Error processing frame: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbbef3-c05a-402a-8949-0fbe48080bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbfb08-20cb-4bb6-a050-325708062977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9934a4-e819-467b-b0bc-1785e330824e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
